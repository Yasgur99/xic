# Programming Assignment 2 - Implementing Semantic Analysis

## Collaborators
* Michael Maitland, mtm68
* Scott Bass, sb2383
* Michael Tobin, mat292

## Running the Program

**Main class:** `mtm68.Main.java`

Run `xic-build` (this requires having Maven installed). Then `xic [options...] <source-files>` becomes available.

## Summary

We found that accounting for all the different possible legal syntax to be challenging. There were a lot of semantically illegal but syntactically legal structures that we would think of and have to add to our parser's abilities (for example true[3]). Design-wise, we had to decide how we were going to both create our grammar and also structure our AST. The AST design followed very closely once we had our grammar since most nonterminals simply corresponded to a node type in our AST. As for our grammar, we had to sit down and draw up a class hierarchy that is inspired by the partial S-Expression grammar given in the writeup. A lot of the issues we ran into while programming were unfortunately integration issues with jcup and jflex as well as different build errors due to versioning issues. These are always frustrating to solve, but once we got them out of the way, we were able to go into a comfortable workflow. Bugs of course came up here and there but were no big deal to resolve.

## Specification

**INSERT**
- Empty file spec?

## Design and Implementation 
### Architecture ###
The key classes and packages we created or updated for this assignment are the following...
 
- mtm68.Main.java
    - Our Main functions very similarly to the previous assignment. We simply added parsing to the program pipeline as well as command line options for outputting a .parsed file and specifying a source path.
 				  
- mtm68.parser.Parser.java & mtm68.parser.xi.cup
    - Parser is the autogenerated class created by Cup. We have modified our lexer.flex in order to allow for seamless integration with cup. This required making our Tokens extend ComplexSymbol which allowed them to be directly passed directly from the lexer to the parser during parsing. We created a TokenFactory class which takes in info from the Lexer (such as token type and location) and constructs into the format that the parser expects. 
    - Our cup is organized quite similarly to the S-Expression spec in the assignment writeup. Our main non-terminals are Program, Interface, Expr, Decl, Use, and Statement. We then have a number of other nonterminals that deal with list construction of different types of nonterminals (i.e. use_star). These types of nonterminals are named based on a regex-like construction (i.e. use_star = use*). Each match returns a result that corresponds to the objects AST node (which is discussed in general further down).
    
- mtm68.ast.nodes & mtm68.ast.nodes.binary & mtm68.ast.nodes.stmts & mtm68.ast.types
    - In these packages, we have created a sizable number of classes that correspond to all of the different possible AST nodes. These nodes correspond directly to the nonterminals in our cup file (i.e. exp:e1 ADD exp:e2 --> Add(e1, e2)). We have established a hierarchy in order to reduce boilerplate code and maintain an organized structure. A great example of this is how all binary operations such as Add and Mult extend our BinExpr class. This came in handy when implementing pretty-printing and will also be useful in the future when creating typechecking and other passes through the AST. This structure will allow for less code repetition.
    
- mtm68.lexer.FileTypeLexer.java
    - This is a wrapper class for the Lexer generated by flex. This wrapper class is what is passed to the parser. It's main purpose is to help the parser tell whether the file being parsed is a program or an interface file. It does this by passing the parser either a XI or IXI token upon the parsers first call to the lexer's next_token method and then simply giving the rest of the tokens normally. We felt this was important to address as the parser can tell whether or not it is parsing a program or interface on its own but it is important that what it is parsing matches the filetype. For example, without these tokens, the parser would parse a perfectly normal program stored in an interface file and not complain (which is bad).
    
### Code Design ###
- For this assignment, we had to implement was a tree traversal for pretty printing. Essentially each node of our AST have to implement a prettyPrint(SExpPrinter p) method. This allows us to call prettyPrint on the root node which then propagates throughout the rest of the tree in order to print the S-Expression model.
- The main data structure we used was a simple tree to maintain our AST as it was built by the parser. Each node is slightly different based on its subcomponents. For example, an ADD node must maintain two child expressions that are operands. Another example is that a FunctionDefn node has a FunctionDecl child and a Block child which represent its declaration and function body.
- Early on, we decided not to use a Visitor structure for our pretty print setup (as we were unsure how/if it would fit later parts of the project well). Of course after our class lecture on the visitor structure we were a little disappointed that we hadn't used it. Perhaps we will incorporate the structure later regardless.

### Programming ###
- Once again, we ran into a lot of interesting errors for our build and also incorporating Jflex and cup. These errors were often tough to chase down due to unhelpful error messages but fortunately we were able to solve them after a bit of debugging.
- The following is the team coding/responsibility breakdown for this assignment...
    - **Tobin:** 
       - command line options
       - jcup spec
       - pretty printing
    - **Maitland:**
        - fixing lexer errors
        - new lexer tests
        - parser tests 
    - **Bass:**
        - jcup spec
        - AST nodes 
 - We, of course, reused our lexer code from the previous assignment. There were a number of errors that we had to fix (mostly involving strings) and also a few slight changes to handle cup integration. This is discussed in the architecture section.
 
## Testing
First, we added a number of tests to our Lexer test suite to address the errors we ran into during PA1 grading. We added a test case to corresepond to each of the failing test cases from the grading. This allowed us to systematically address each of the errors and ensure that they were all fixed. A lot of the errors had to deal with matching on escaped characters in character literals. We fixed these by adding cases for the lexer to match on for each of them.

In order to test our code, we utilized a suite of JUnit tests. These tests ensure that we correctly parse and construct an AST for a given program. This time around, there were a lot more different edge cases and structures in general to test. This required really considering different and unusual syntactically legal programs which was a challenge in itself. Our tests are structured to create dummy programs which encased the structures we wanted to test. Then we are able to assert different things about the AST returned.

We also created a test suite for pretty printing to check that our structure was being outputted correctly. These test cases incorporated a few of the release tests as well as some of our own design. 

## Work plan

We began by splitting up the work such that Maitland would address flaws in our lexer as well as jcup integration while Bass and Tobin worked on the grammar and cup speec. This allowed us to accomplish two big tasks in parallel without holding each other back. Then, we caught each other up to speed and carried out testing together to make sure everyone understood the code and that it was correct.

This plan allowed for us to work in parallel which increased our efficiency. We also partitioned the work such that each component was well-isolated which meant that there wasn't much need for code redesign. We had also discussed what was expected of each component prior to implementation such that we were all on the same page for the big picture.

## Known Problems

**INSERT**

## Comments

NA

